###############################################################################
# Docker Compose – Multi-Container-Entwicklungsumgebung
#
# Enthält fünf Services:
#   1) devcontainer   – VS Code-Attach-Punkt (Python + Jupyter)
#   2) elasticsearch  – Index-Engine (Single-Node)
#   3) snomed-import  – ⚡ Einmaliger RF2-Importer (Profil „init“)
#   4) snowstorm      – Terminologie-Server (REST API)
#   5) browser        – Schlanke Web-UI für SNOMED CT
#
# Netzwerk-Modell:
#   Alle Services liegen im automatisch erzeugten Compose-Standardnetz.
#   → Jeder Dienst ist per Service-Namen erreichbar:
#       http://elasticsearch:9200  |  http://snowstorm:8080
#
# Persistenz:
#   • elastic-Volume  → Elasticsearch-Daten (Indizes)
#   • notebooks-Volume → Jupyter-Notebooks
#   RF2-ZIPs liegen **außerhalb** von Docker im Host-Ordner
#   „./snomedct_releases“ (siehe snomed-import → bind-mount).
###############################################################################
version: '2.1'

services:
  ###########################################################################
  # 1) devcontainer – Dein Arbeits-/Editor-Container
  # ------------------------------------------------------------------------
  # • Wird aus dem lokalen Dockerfile gebaut (Python 3.11 + Tools).
  # • VS Code „attach“t hier hinein (Command: sleep infinity).
  # • Wartet, bis snowstorm läuft (depends_on), damit Notebooks sofort
  #   gegen die API testen können.
  ###########################################################################
  devcontainer:
    volumes:
      - ../:/workspaces/piskklis
    build:
      context: .                 # Projekt-Root als Build-Kontext
      dockerfile: Dockerfile     # definiert Python, Jupyter, Git …
    command: sleep infinity       # hält den Container im Leerlauf

    depends_on:
      snowstorm:                  # startet erst, wenn API gesund
        condition: service_healthy

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - node.name=snowstorm
      - cluster.name=snowstorm-cluster
      - "ES_JAVA_OPTS=-Xms4g -Xmx4g"
    volumes:
      - elastic:/usr/share/elasticsearch/data
    networks:
      elastic:
        aliases:
        - es
    healthcheck:
      test: ["CMD", "curl", "-f", "http://es:9200"]
      interval: 10s
      timeout: 10s
      retries: 60
    ports:
      - 127.0.0.1:9200:9200
    mem_reservation: 4g


  snowstorm:
    image: snomedinternational/snowstorm:latest
    container_name: snowstorm
    restart: always
    depends_on:
      elasticsearch:
        condition: service_healthy
    entrypoint: java -Xms2g -Xmx4g --add-opens java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED -cp @/app/jib-classpath-file org.snomed.snowstorm.SnowstormApplication --elasticsearch.urls=http://es:9200
    networks:
      elastic:
        aliases:
        - snowstorm
    ports:
      - 8080:8080

    healthcheck:
      # Befehl, der ausgeführt wird: „curl -f“ (fail if HTTP error)
      #   → schlägt fehl, falls HTTP-Status nicht 200.
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]

      # Wie oft wird getestet? Hier alle 5 Sekunden.
      interval: 30s

      # Wie lange darf ein Test maximal dauern, bevor er als fehlgeschlagen gilt?
      timeout: 3s

      # Nach wie vielen Fehlversuchen wird der Container als „unhealthy“ markiert?
      retries: 24
      # (In diesem Beispiel: 24 × 5 s = 2 Minuten maximale Wartezeit)

  browser:
    image: snomedinternational/snomedct-browser:latest
    container_name: browser
    depends_on:
      - snowstorm
    links:
      - snowstorm:snowstorm
    networks:
      - elastic
    environment:
      - API_HOST=http://snowstorm:8080/
    ports:
      - 80:80
    restart: always


networks:
  elastic:

volumes:
  elastic: