###############################################################################
# Docker Compose â€“ Multi-Container-Entwicklungsumgebung
#
# EnthÃ¤lt fÃ¼nf Services:
#   1) devcontainer   â€“ VS Code-Attach-Punkt (Python + Jupyter)
#   2) elasticsearch  â€“ Index-Engine (Single-Node)
#   3) snomed-import  â€“ âš¡ Einmaliger RF2-Importer (Profil â€žinitâ€œ)
#   4) snowstorm      â€“ Terminologie-Server (REST API)
#   5) browser        â€“ Schlanke Web-UI fÃ¼r SNOMED CT
#
# Netzwerk-Modell:
#   Alle Services liegen im automatisch erzeugten Compose-Standardnetz.
#   â†’ Jeder Dienst ist per Service-Namen erreichbar:
#       http://elasticsearch:9200  |  http://snowstorm:8080
#
# Persistenz:
#   â€¢ elastic-Volume  â†’ Elasticsearch-Daten (Indizes)
#   â€¢ notebooks-Volume â†’ Jupyter-Notebooks
#   RF2-ZIPs liegen **auÃŸerhalb** von Docker im Host-Ordner
#   â€ž./snomedct_releasesâ€œ (siehe snomed-import â†’ bind-mount).
###############################################################################

services:
  ###########################################################################
  # 1) devcontainer â€“ Dein Arbeits-/Editor-Container
  # ------------------------------------------------------------------------
  # â€¢ Wird aus dem lokalen Dockerfile gebaut (Python 3.11 + Tools).
  # â€¢ VS Code â€žattachâ€œt hier hinein (Command: sleep infinity).
  # â€¢ Wartet, bis snowstorm lÃ¤uft (depends_on), damit Notebooks sofort
  #   gegen die API testen kÃ¶nnen.
  ###########################################################################
  devcontainer:
    build:
      context: .                 # Projekt-Root als Build-Kontext
      dockerfile: Dockerfile     # definiert Python, Jupyter, Git â€¦
    volumes:
      - notebooks:/workspace/notebooks   # Persistente .ipynb-Dateien
    command: sleep infinity       # hÃ¤lt den Container im Leerlauf
    depends_on:
      snowstorm:                  # startet erst, wenn API gesund
        condition: service_healthy


  ###########################################################################
  # 2) elasticsearch â€“ Single-Node Cluster (DEV-Modus)
  # ------------------------------------------------------------------------
  # â€¢ 4 GB Java-Heap â€“ stelle sicher, dass der Codespace/VM > 6 GB RAM hat.
  # â€¢ Daten werden im Volume â€želasticâ€œ gespeichert â†’ bleiben auch nach
  #   Container-Rebuild erhalten.
  ###########################################################################
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2
    environment:
      - discovery.type=single-node         # Single-Node-Modus, kein Cluster-Bootstrap nÃ¶tig
      - xpack.security.enabled=false       # Sicherheit deaktiviert (nur fÃ¼r Entwicklung!)
      - "ES_JAVA_OPTS=-Xms4g -Xmx4g"       # Fester Java-Heap, hier 4 GB
    volumes:
      - elastic:/usr/share/elasticsearch/data  # Persistente Speicherung der ES-Daten

    healthcheck:
      # Healthcheck prÃ¼ft regelmÃ¤ÃŸig, ob Elasticsearch voll funktionsfÃ¤hig ist.
      # Das ist wichtig, damit nachfolgende Container (wie z.B. Importer oder Snowstorm)
      # nicht zu frÃ¼h starten und auf einen noch nicht einsatzbereiten Cluster zugreifen.
      #
      # test: 
      #   - 'curl' schickt eine HTTP-Anfrage an Elasticsearch auf Port 9200.
      #   - '-f' sorgt dafÃ¼r, dass curl einen Fehlercode zurÃ¼ckgibt, falls die Antwort kein 2xx-Status ist.
      #   - Der Endpunkt '/_cluster/health?wait_for_status=green' prÃ¼ft, ob der Cluster den Status 'green' erreicht hat.
      #     Mit 'wait_for_status=green' wartet Elasticsearch kurz, ob der Status noch wechselt.
      #   - '|| exit 1' bedeutet: Falls curl fehlschlÃ¤gt (also Status â‰  green oder Fehler), wird mit Fehlercode 1 abgebrochen.
      #   - Docker Compose markiert den Service dann als 'unhealthy' und startet abhÃ¤ngige Container noch nicht.
      test: |
        sh -c '
          echo "ðŸ” PrÃ¼fe Elasticsearch-Statusâ€¦";
          curl -f http://localhost:9200/_cluster/health?wait_for_status=green || exit 1
        '
      interval: 30s    # Alle 30 Sekunden wird der Healthcheck erneut versucht.
      timeout: 10s     # Nach 10 Sekunden bricht jeder einzelne Versuch ab.
      retries: 120      # Es werden maximal 120 Versuche gemacht (also bis zu 60 Minuten).

  snowstorm:
    # Das offizielle Snowstorm-Docker-Image (enthÃ¤lt die Java-App)
    image: snomedinternational/snowstorm:latest

    # -------------------------------------------------------------------------
    # ENTRYPOINT: Startet die Anwendung exakt so wie im offiziellen Compose-File.
    # -Xms2g -Xmx4g                  â†’ 2â€“4 GB Heap fÃ¼r Java (je nach VM-GrÃ¶ÃŸe)
    # --add-opens ...                â†’ notwendige Java-Module fÃ¼r Snowstorm
    # -cp @/app/jib-classpath-file   â†’ Klassenpfad (so funktioniert das Image, kein JAR!)
    # org.snomed.snowstorm.SnowstormApplication
    #                                â†’ Hauptklasse, die Snowstorm startet
    # --elasticsearch.urls=...       â†’ Adresse des Elasticsearch-Service (per Compose vernetzt)
    # -------------------------------------------------------------------------

    # â†’ Hier das ZIP aus dem Codespace mounten:
    # volumes:
    # - ./snomedct_releases/SnomedCT_Germany-EditionRelease_PRODUCTION_20250515T120000Z.zip:/data/SnomedCT.zip:ro
      
    entrypoint: >
      java -Xms2g -Xmx4g
      --add-opens java.base/java.lang=ALL-UNNAMED
      --add-opens java.base/java.util=ALL-UNNAMED
      -cp @/app/jib-classpath-file
      org.snomed.snowstorm.SnowstormApplication
      --elasticsearch.urls=http://elasticsearch:9200
      --server.address=0.0.0.0

    # -------------------------------------------------------------------------
    # depends_on: Wartet, bis Elasticsearch â€žhealthyâ€œ ist
    # (d. h. HTTP auf Port 9200 antwortet), bevor Snowstorm startet.
    # So werden Verbindungsfehler beim Initialisieren verhindert.
    # -------------------------------------------------------------------------
    depends_on:
      elasticsearch:
        condition: service_healthy
      # snomed-import:
      #   condition: service_completed_successfully

    # Healthcheck fÃ¼r Snowstorm-Container:
    #   â€¢ PrÃ¼ft regelmÃ¤ÃŸig, ob die REST-API unter /actuator/health erreichbar ist.
    #   â€¢ Erst wenn dieser Test erfolgreich ist, gilt der Container als â€žhealthyâ€œ.
    #   â€¢ Docker Compose kann so AbhÃ¤ngigkeiten zuverlÃ¤ssig steuern (z.B. browser).
    # -------------------------------------------------------------------------
    healthcheck:
      # Befehl, der ausgefÃ¼hrt wird: â€žcurl -fâ€œ (fail if HTTP error)
      #   â†’ schlÃ¤gt fehl, falls HTTP-Status nicht 200.
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]

      # Wie oft wird getestet? Hier alle 5 Sekunden.
      interval: 30s

      # Wie lange darf ein Test maximal dauern, bevor er als fehlgeschlagen gilt?
      timeout: 3s

      # Nach wie vielen Fehlversuchen wird der Container als â€žunhealthyâ€œ markiert?
      retries: 24
      # (In diesem Beispiel: 24 Ã— 5â€¯s = 2 Minuten maximale Wartezeit)

  ###########################################################################
  # 5) browser â€“ Schlanke Web-UI (Port 80) zum DurchstÃ¶bern von SNOMED CT
  ###########################################################################
  browser:
    image: snomedinternational/snomedct-browser:latest
    environment:
      - API_HOST=http://snowstorm:8080/    # zeigt auf REST-API
    depends_on:
      snowstorm:
        condition: service_healthy

      
###############################################################################
# Benannte Docker-Volumes
# ---------------------------------------------------------------------------
# â€¢ elastic   â†’ persistente Elasticsearch-Indizes
# â€¢ notebooks â†’ Jupyter-Notebooks (Workspace)
###############################################################################
volumes:
  elastic:
  notebooks:
